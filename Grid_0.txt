exploring: random action
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:17
exploring: random action
total reward:15
Episode: 0.005Total Reward: 15Total Steps: 4Epsilon: 1.0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
exploring: random action
total reward:-2
Episode: 1.005Total Reward: -2Total Steps: 1Epsilon: 1.0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
exploring: random action
total reward:-1
exploring: random action
total reward:8
exploring: random action
total reward:6
Episode: 2.005Total Reward: 6Total Steps: 3Epsilon: 1.0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
exploring: random action
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:27
exploring: random action
total reward:26
exploring: random action
total reward:35
exploring: random action
total reward:44
exploring: random action
total reward:43
exploring: random action
total reward:52
exploring: random action
total reward:51
exploring: random action
total reward:50
exploring: random action
total reward:48
Episode: 3.005Total Reward: 48Total Steps: 11Epsilon: 1.0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 4.005Total Reward: 7Total Steps: 2Epsilon: 0.9
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 5.005Total Reward: 7Total Steps: 2Epsilon: 0.81
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:7
Episode: 6.005Total Reward: 7Total Steps: 2Epsilon: 0.7290000000000001
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploiting: q-values predicted from network
-------------------------------
total reward:8
exploring: random action
total reward:17
exploring: random action
total reward:16
exploring: random action
total reward:25
exploring: random action
total reward:23
Episode: 7.005Total Reward: 23Total Steps: 6Epsilon: 0.6561000000000001
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploiting: q-values predicted from network
-------------------------------
total reward:-3
Episode: 8.005Total Reward: -3Total Steps: 2Epsilon: 0.5904900000000002
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:16
Episode: 9.005Total Reward: 16Total Steps: 3Epsilon: 0.5314410000000002
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:25
Episode: 10.005Total Reward: 25Total Steps: 4Epsilon: 0.47829690000000014
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploiting: q-values predicted from network
-------------------------------
total reward:8
exploring: random action
total reward:7
exploiting: q-values predicted from network
-------------------------------
total reward:5
Episode: 11.005Total Reward: 5Total Steps: 4Epsilon: 0.43046721000000016
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 12.005Total Reward: 7Total Steps: 2Epsilon: 0.38742048900000015
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 13.005Total Reward: 7Total Steps: 2Epsilon: 0.34867844010000015
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 14.005Total Reward: 7Total Steps: 2Epsilon: 0.31381059609000017
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 15.005Total Reward: 7Total Steps: 2Epsilon: 0.28242953648100017
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 16.005Total Reward: 7Total Steps: 2Epsilon: 0.25418658283290013
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 17.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 18.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 19.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:16
Episode: 20.005Total Reward: 16Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:7
Episode: 21.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 22.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:16
Episode: 23.005Total Reward: 16Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 24.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 25.005Total Reward: -2Total Steps: 1Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 26.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 27.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 28.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 29.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:7
Episode: 30.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 31.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 32.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 33.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 34.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 35.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 36.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 37.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 38.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 39.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 40.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 41.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:7
Episode: 42.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 43.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 44.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 45.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 46.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 47.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 48.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 49.005Total Reward: -2Total Steps: 1Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:33
Episode: 50.005Total Reward: 33Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 51.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 52.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 53.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 54.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:7
Episode: 55.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:15
Episode: 56.005Total Reward: 15Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 57.005Total Reward: -2Total Steps: 1Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:6
Episode: 58.005Total Reward: 6Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:16
Episode: 59.005Total Reward: 16Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 60.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:15
Episode: 61.005Total Reward: 15Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 62.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 63.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 64.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 65.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 66.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 67.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:16
Episode: 68.005Total Reward: 16Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploring: random action
total reward:33
Episode: 69.005Total Reward: 33Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:24
Episode: 70.005Total Reward: 24Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:25
Episode: 71.005Total Reward: 25Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:16
Episode: 72.005Total Reward: 16Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:6
Episode: 73.005Total Reward: 6Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 74.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploiting: q-values predicted from network
-------------------------------
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:6
Episode: 75.005Total Reward: 6Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:7
Episode: 76.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 77.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 78.005Total Reward: -2Total Steps: 1Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:25
Episode: 79.005Total Reward: 25Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploring: random action
total reward:44
exploring: random action
total reward:53
exploring: random action
total reward:52
exploiting: q-values predicted from network
-------------------------------
total reward:61
exploiting: q-values predicted from network
-------------------------------
total reward:70
exploiting: q-values predicted from network
-------------------------------
total reward:68
Episode: 80.005Total Reward: 68Total Steps: 11Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 81.005Total Reward: -2Total Steps: 1Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:25
Episode: 82.005Total Reward: 25Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:25
Episode: 83.005Total Reward: 25Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:34
Episode: 84.005Total Reward: 34Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:7
Episode: 85.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 86.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:34
Episode: 87.005Total Reward: 34Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploiting: q-values predicted from network
-------------------------------
total reward:8
exploring: random action
total reward:6
Episode: 88.005Total Reward: 6Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:25
Episode: 89.005Total Reward: 25Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 90.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:25
Episode: 91.005Total Reward: 25Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 92.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:-3
Episode: 93.005Total Reward: -3Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 94.005Total Reward: -2Total Steps: 1Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:25
Episode: 95.005Total Reward: 25Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploring: random action
total reward:43
Episode: 96.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:54
exploiting: q-values predicted from network
-------------------------------
total reward:63
exploring: random action
total reward:61
Episode: 97.005Total Reward: 61Total Steps: 8Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:34
Episode: 98.005Total Reward: 34Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploiting: q-values predicted from network
-------------------------------
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploring: random action
total reward:33
Episode: 99.005Total Reward: 33Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 100.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:25
Episode: 101.005Total Reward: 25Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 102.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploiting: q-values predicted from network
-------------------------------
total reward:62
exploiting: q-values predicted from network
-------------------------------
total reward:60
Episode: 103.005Total Reward: 60Total Steps: 9Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploiting: q-values predicted from network
-------------------------------
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:33
Episode: 104.005Total Reward: 33Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:34
Episode: 105.005Total Reward: 34Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:-3
Episode: 106.005Total Reward: -3Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:34
Episode: 107.005Total Reward: 34Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 108.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 109.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 110.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:42
Episode: 111.005Total Reward: 42Total Steps: 7Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:25
Episode: 112.005Total Reward: 25Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 113.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 114.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:34
Episode: 115.005Total Reward: 34Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:54
exploring: random action
total reward:53
exploring: random action
total reward:51
Episode: 116.005Total Reward: 51Total Steps: 8Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 117.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploring: random action
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploiting: q-values predicted from network
-------------------------------
total reward:62
exploiting: q-values predicted from network
-------------------------------
total reward:71
exploiting: q-values predicted from network
-------------------------------
total reward:69
Episode: 118.005Total Reward: 69Total Steps: 10Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:34
Episode: 119.005Total Reward: 34Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:34
Episode: 120.005Total Reward: 34Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:36
exploring: random action
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploiting: q-values predicted from network
-------------------------------
total reward:62
exploiting: q-values predicted from network
-------------------------------
total reward:60
Episode: 121.005Total Reward: 60Total Steps: 9Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploiting: q-values predicted from network
-------------------------------
total reward:51
Episode: 122.005Total Reward: 51Total Steps: 8Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:34
Episode: 123.005Total Reward: 34Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 124.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploring: random action
total reward:26
exploring: random action
total reward:24
Episode: 125.005Total Reward: 24Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:27
exploring: random action
total reward:26
exploring: random action
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploring: random action
total reward:42
Episode: 126.005Total Reward: 42Total Steps: 7Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 127.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploring: random action
total reward:15
Episode: 128.005Total Reward: 15Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 129.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 130.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:34
Episode: 131.005Total Reward: 34Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 132.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:25
Episode: 133.005Total Reward: 25Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 134.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 135.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploiting: q-values predicted from network
-------------------------------
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploring: random action
total reward:24
Episode: 136.005Total Reward: 24Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 137.005Total Reward: -2Total Steps: 1Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploring: random action
total reward:24
Episode: 138.005Total Reward: 24Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:34
Episode: 139.005Total Reward: 34Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 140.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:33
Episode: 141.005Total Reward: 33Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploiting: q-values predicted from network
-------------------------------
total reward:62
exploring: random action
total reward:60
Episode: 142.005Total Reward: 60Total Steps: 9Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 143.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 144.005Total Reward: -2Total Steps: 1Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:16
Episode: 145.005Total Reward: 16Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 146.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploring: random action
total reward:34
exploiting: q-values predicted from network
-------------------------------
total reward:43
exploiting: q-values predicted from network
-------------------------------
total reward:52
exploiting: q-values predicted from network
-------------------------------
total reward:61
exploiting: q-values predicted from network
-------------------------------
total reward:70
exploiting: q-values predicted from network
-------------------------------
total reward:79
exploring: random action
total reward:77
Episode: 147.005Total Reward: 77Total Steps: 12Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploring: random action
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploiting: q-values predicted from network
-------------------------------
total reward:51
Episode: 148.005Total Reward: 51Total Steps: 8Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploiting: q-values predicted from network
-------------------------------
total reward:62
exploiting: q-values predicted from network
-------------------------------
total reward:60
Episode: 149.005Total Reward: 60Total Steps: 9Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:33
Episode: 150.005Total Reward: 33Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploring: random action
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploiting: q-values predicted from network
-------------------------------
total reward:62
exploiting: q-values predicted from network
-------------------------------
total reward:60
Episode: 151.005Total Reward: 60Total Steps: 9Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploring: random action
total reward:16
exploiting: q-values predicted from network
-------------------------------
total reward:25
exploiting: q-values predicted from network
-------------------------------
total reward:34
exploiting: q-values predicted from network
-------------------------------
total reward:43
exploiting: q-values predicted from network
-------------------------------
total reward:52
exploiting: q-values predicted from network
-------------------------------
total reward:50
Episode: 152.005Total Reward: 50Total Steps: 9Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:17
exploring: random action
total reward:26
exploring: random action
total reward:25
exploiting: q-values predicted from network
-------------------------------
total reward:34
exploring: random action
total reward:43
exploiting: q-values predicted from network
-------------------------------
total reward:52
exploiting: q-values predicted from network
-------------------------------
total reward:50
Episode: 153.005Total Reward: 50Total Steps: 9Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:24
Episode: 154.005Total Reward: 24Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:16
Episode: 155.005Total Reward: 16Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:25
Episode: 156.005Total Reward: 25Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:25
Episode: 157.005Total Reward: 25Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:27
exploring: random action
total reward:36
exploring: random action
total reward:45
exploring: random action
total reward:43
Episode: 158.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:16
Episode: 159.005Total Reward: 16Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:16
Episode: 160.005Total Reward: 16Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 161.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 162.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 163.005Total Reward: -2Total Steps: 1Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 164.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploiting: q-values predicted from network
-------------------------------
total reward:62
exploiting: q-values predicted from network
-------------------------------
total reward:60
Episode: 165.005Total Reward: 60Total Steps: 9Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploiting: q-values predicted from network
-------------------------------
total reward:62
exploiting: q-values predicted from network
-------------------------------
total reward:60
Episode: 166.005Total Reward: 60Total Steps: 9Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 167.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploring: random action
total reward:44
exploring: random action
total reward:42
Episode: 168.005Total Reward: 42Total Steps: 7Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:42
Episode: 169.005Total Reward: 42Total Steps: 7Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploiting: q-values predicted from network
-------------------------------
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploring: random action
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploiting: q-values predicted from network
-------------------------------
total reward:62
exploiting: q-values predicted from network
-------------------------------
total reward:60
Episode: 170.005Total Reward: 60Total Steps: 9Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploring: random action
total reward:43
Episode: 171.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 172.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploring: random action
total reward:15
Episode: 173.005Total Reward: 15Total Steps: 4Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:7
Episode: 174.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 175.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 176.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:6
Episode: 177.005Total Reward: 6Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 178.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 179.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 180.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:7
Episode: 181.005Total Reward: 7Total Steps: 2Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:26
exploring: random action
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploring: random action
total reward:42
Episode: 182.005Total Reward: 42Total Steps: 7Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploiting: q-values predicted from network
-------------------------------
total reward:62
exploiting: q-values predicted from network
-------------------------------
total reward:71
exploiting: q-values predicted from network
-------------------------------
total reward:69
Episode: 183.005Total Reward: 69Total Steps: 10Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:35
exploring: random action
total reward:44
exploring: random action
total reward:43
exploiting: q-values predicted from network
-------------------------------
total reward:52
exploiting: q-values predicted from network
-------------------------------
total reward:61
exploiting: q-values predicted from network
-------------------------------
total reward:70
exploiting: q-values predicted from network
-------------------------------
total reward:68
Episode: 184.005Total Reward: 68Total Steps: 11Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 185.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:6
Episode: 186.005Total Reward: 6Total Steps: 3Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 187.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:34
Episode: 188.005Total Reward: 34Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploiting: q-values predicted from network
-------------------------------
total reward:62
exploiting: q-values predicted from network
-------------------------------
total reward:71
exploiting: q-values predicted from network
-------------------------------
total reward:80
exploring: random action
total reward:79
exploiting: q-values predicted from network
-------------------------------
total reward:77
Episode: 189.005Total Reward: 77Total Steps: 12Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 190.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 191.005Total Reward: -2Total Steps: 1Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:42
Episode: 192.005Total Reward: 42Total Steps: 7Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploring: random action
total reward:35
exploring: random action
total reward:33
Episode: 193.005Total Reward: 33Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 194.005Total Reward: -2Total Steps: 1Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 195.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploring: random action
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:42
Episode: 196.005Total Reward: 42Total Steps: 7Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:43
Episode: 197.005Total Reward: 43Total Steps: 6Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploring: random action
total reward:24
Episode: 198.005Total Reward: 24Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploiting: q-values predicted from network
-------------------------------
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploring: random action
total reward:24
Episode: 199.005Total Reward: 24Total Steps: 5Epsilon: 0.22876792454961012
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
