exploring: random action
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:7
exploring: random action
total reward:5
Episode: 0.01Total Reward: 5Total Steps: 4Epsilon: 1.0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
exploring: random action
total reward:-1
exploring: random action
total reward:8
exploring: random action
total reward:7
exploring: random action
total reward:5
Episode: 1.01Total Reward: 5Total Steps: 4Epsilon: 1.0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
exploring: random action
total reward:-2
Episode: 2.01Total Reward: -2Total Steps: 1Epsilon: 1.0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 3.01Total Reward: 7Total Steps: 2Epsilon: 1.0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
exploring: random action
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:17
exploring: random action
total reward:16
exploring: random action
total reward:15
exploring: random action
total reward:13
Episode: 4.01Total Reward: 13Total Steps: 6Epsilon: 1.0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:17
exploring: random action
total reward:15
Episode: 5.01Total Reward: 15Total Steps: 4Epsilon: 0.995
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:17
exploring: random action
total reward:15
Episode: 6.01Total Reward: 15Total Steps: 4Epsilon: 0.990025
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:-3
Episode: 7.01Total Reward: -3Total Steps: 2Epsilon: 0.985074875
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:8
exploring: random action
total reward:6
Episode: 8.01Total Reward: 6Total Steps: 3Epsilon: 0.9801495006250001
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 9.01Total Reward: -2Total Steps: 1Epsilon: 0.9752487531218751
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:17
exploring: random action
total reward:15
Episode: 10.01Total Reward: 15Total Steps: 4Epsilon: 0.9703725093562657
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 11.01Total Reward: -2Total Steps: 1Epsilon: 0.9655206468094844
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 12.01Total Reward: -2Total Steps: 1Epsilon: 0.960693043575437
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:17
exploring: random action
total reward:15
Episode: 13.01Total Reward: 15Total Steps: 4Epsilon: 0.9558895783575597
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:-3
Episode: 14.01Total Reward: -3Total Steps: 2Epsilon: 0.9511101304657719
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 15.01Total Reward: -2Total Steps: 1Epsilon: 0.946354579813443
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 16.01Total Reward: -2Total Steps: 1Epsilon: 0.9416228069143757
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 17.01Total Reward: -2Total Steps: 1Epsilon: 0.9369146928798039
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:8
exploring: random action
total reward:6
Episode: 18.01Total Reward: 6Total Steps: 3Epsilon: 0.9322301194154049
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:8
exploring: random action
total reward:7
exploring: random action
total reward:16
exploring: random action
total reward:14
Episode: 19.01Total Reward: 14Total Steps: 5Epsilon: 0.9275689688183278
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:8
exploring: random action
total reward:6
Episode: 20.01Total Reward: 6Total Steps: 3Epsilon: 0.9229311239742362
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 21.01Total Reward: -2Total Steps: 1Epsilon: 0.918316468354365
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 22.01Total Reward: -2Total Steps: 1Epsilon: 0.9137248860125932
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:6
Episode: 23.01Total Reward: 6Total Steps: 3Epsilon: 0.9091562615825302
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:17
exploring: random action
total reward:15
Episode: 24.01Total Reward: 15Total Steps: 4Epsilon: 0.9046104802746175
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:24
Episode: 25.01Total Reward: 24Total Steps: 5Epsilon: 0.9000874278732445
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 26.01Total Reward: 7Total Steps: 2Epsilon: 0.8955869907338783
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 27.01Total Reward: 7Total Steps: 2Epsilon: 0.8911090557802088
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:27
exploring: random action
total reward:26
exploring: random action
total reward:25
exploring: random action
total reward:34
exploiting: q-values predicted from network
-------------------------------
total reward:43
exploring: random action
total reward:41
Episode: 28.01Total Reward: 41Total Steps: 8Epsilon: 0.8866535105013078
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 29.01Total Reward: -2Total Steps: 1Epsilon: 0.8822202429488013
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 30.01Total Reward: -2Total Steps: 1Epsilon: 0.8778091417340573
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:17
exploring: random action
total reward:26
exploring: random action
total reward:24
Episode: 31.01Total Reward: 24Total Steps: 5Epsilon: 0.8734200960253871
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:15
Episode: 32.01Total Reward: 15Total Steps: 4Epsilon: 0.8690529955452602
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 33.01Total Reward: -2Total Steps: 1Epsilon: 0.8647077305675338
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 34.01Total Reward: 7Total Steps: 2Epsilon: 0.8603841919146962
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:7
exploiting: q-values predicted from network
-------------------------------
total reward:16
exploring: random action
total reward:15
exploring: random action
total reward:13
Episode: 35.01Total Reward: 13Total Steps: 6Epsilon: 0.8560822709551227
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:8
exploring: random action
total reward:6
Episode: 36.01Total Reward: 6Total Steps: 3Epsilon: 0.851801859600347
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 37.01Total Reward: 7Total Steps: 2Epsilon: 0.8475428503023453
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 38.01Total Reward: 7Total Steps: 2Epsilon: 0.8433051360508336
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:17
exploring: random action
total reward:26
exploring: random action
total reward:25
exploring: random action
total reward:34
exploring: random action
total reward:32
Episode: 39.01Total Reward: 32Total Steps: 7Epsilon: 0.8390886103705794
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 40.01Total Reward: 7Total Steps: 2Epsilon: 0.8348931673187264
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 41.01Total Reward: 7Total Steps: 2Epsilon: 0.8307187014821328
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 42.01Total Reward: -2Total Steps: 1Epsilon: 0.8265651079747222
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:16
Episode: 43.01Total Reward: 16Total Steps: 3Epsilon: 0.8224322824348486
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:27
exploring: random action
total reward:25
Episode: 44.01Total Reward: 25Total Steps: 4Epsilon: 0.8183201210226743
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:-3
Episode: 45.01Total Reward: -3Total Steps: 2Epsilon: 0.8142285204175609
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:16
Episode: 46.01Total Reward: 16Total Steps: 3Epsilon: 0.810157377815473
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:17
exploring: random action
total reward:15
Episode: 47.01Total Reward: 15Total Steps: 4Epsilon: 0.8061065909263957
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 48.01Total Reward: 7Total Steps: 2Epsilon: 0.8020760579717637
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:7
Episode: 49.01Total Reward: 7Total Steps: 2Epsilon: 0.798065677681905
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 50.01Total Reward: -2Total Steps: 1Epsilon: 0.7940753492934954
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:17
exploring: random action
total reward:26
exploring: random action
total reward:25
exploring: random action
total reward:34
exploring: random action
total reward:43
exploring: random action
total reward:52
exploring: random action
total reward:61
exploring: random action
total reward:59
Episode: 51.01Total Reward: 59Total Steps: 10Epsilon: 0.7901049725470279
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:27
exploring: random action
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:24
Episode: 52.01Total Reward: 24Total Steps: 5Epsilon: 0.7861544476842928
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 53.01Total Reward: 7Total Steps: 2Epsilon: 0.7822236754458713
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:8
exploring: random action
total reward:6
Episode: 54.01Total Reward: 6Total Steps: 3Epsilon: 0.778312557068642
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 55.01Total Reward: -2Total Steps: 1Epsilon: 0.7744209942832988
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:25
Episode: 56.01Total Reward: 25Total Steps: 4Epsilon: 0.7705488893118823
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 57.01Total Reward: -2Total Steps: 1Epsilon: 0.7666961448653229
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploiting: q-values predicted from network
-------------------------------
total reward:8
exploring: random action
total reward:7
exploiting: q-values predicted from network
-------------------------------
total reward:16
exploring: random action
total reward:25
exploring: random action
total reward:24
exploring: random action
total reward:22
Episode: 58.01Total Reward: 22Total Steps: 7Epsilon: 0.7628626641409962
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 59.01Total Reward: 7Total Steps: 2Epsilon: 0.7590483508202912
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 60.01Total Reward: 7Total Steps: 2Epsilon: 0.7552531090661897
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:-3
Episode: 61.01Total Reward: -3Total Steps: 2Epsilon: 0.7514768435208588
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 62.01Total Reward: -2Total Steps: 1Epsilon: 0.7477194593032545
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:16
Episode: 63.01Total Reward: 16Total Steps: 3Epsilon: 0.7439808620067382
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploring: random action
total reward:15
Episode: 64.01Total Reward: 15Total Steps: 4Epsilon: 0.7402609576967045
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:16
Episode: 65.01Total Reward: 16Total Steps: 3Epsilon: 0.736559652908221
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:17
exploring: random action
total reward:16
exploring: random action
total reward:15
exploring: random action
total reward:24
exploring: random action
total reward:33
exploring: random action
total reward:31
Episode: 66.01Total Reward: 31Total Steps: 8Epsilon: 0.7328768546436799
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploring: random action
total reward:26
exploring: random action
total reward:35
exploiting: q-values predicted from network
-------------------------------
total reward:44
exploiting: q-values predicted from network
-------------------------------
total reward:53
exploring: random action
total reward:52
exploring: random action
total reward:51
exploiting: q-values predicted from network
-------------------------------
total reward:60
exploring: random action
total reward:59
exploring: random action
total reward:68
exploiting: q-values predicted from network
-------------------------------
total reward:77
exploiting: q-values predicted from network
-------------------------------
total reward:75
Episode: 67.01Total Reward: 75Total Steps: 14Epsilon: 0.7292124703704616
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:16
Episode: 68.01Total Reward: 16Total Steps: 3Epsilon: 0.7255664080186093
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:16
Episode: 69.01Total Reward: 16Total Steps: 3Epsilon: 0.7219385759785162
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 70.01Total Reward: -2Total Steps: 1Epsilon: 0.7183288830986236
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 71.01Total Reward: -2Total Steps: 1Epsilon: 0.7147372386831305
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 72.01Total Reward: -2Total Steps: 1Epsilon: 0.7111635524897149
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 73.01Total Reward: 7Total Steps: 2Epsilon: 0.7076077347272662
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 74.01Total Reward: 7Total Steps: 2Epsilon: 0.7040696960536299
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 75.01Total Reward: 7Total Steps: 2Epsilon: 0.7005493475733617
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:6
Episode: 76.01Total Reward: 6Total Steps: 3Epsilon: 0.697046600835495
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:7
Episode: 77.01Total Reward: 7Total Steps: 2Epsilon: 0.6935613678313175
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 78.01Total Reward: -2Total Steps: 1Epsilon: 0.6900935609921609
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:36
exploiting: q-values predicted from network
-------------------------------
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:54
exploiting: q-values predicted from network
-------------------------------
total reward:63
exploring: random action
total reward:62
exploring: random action
total reward:71
exploiting: q-values predicted from network
-------------------------------
total reward:80
exploring: random action
total reward:78
Episode: 79.01Total Reward: 78Total Steps: 11Epsilon: 0.6866430931872001
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:7
exploring: random action
total reward:6
exploring: random action
total reward:4
Episode: 80.01Total Reward: 4Total Steps: 5Epsilon: 0.6832098777212641
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:17
exploring: random action
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploring: random action
total reward:33
Episode: 81.01Total Reward: 33Total Steps: 6Epsilon: 0.6797938283326578
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:17
exploring: random action
total reward:16
exploring: random action
total reward:15
exploiting: q-values predicted from network
-------------------------------
total reward:24
exploring: random action
total reward:22
Episode: 82.01Total Reward: 22Total Steps: 7Epsilon: 0.6763948591909945
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploring: random action
total reward:8
exploring: random action
total reward:6
Episode: 83.01Total Reward: 6Total Steps: 3Epsilon: 0.6730128848950395
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:8
exploiting: q-values predicted from network
-------------------------------
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploring: random action
total reward:35
exploring: random action
total reward:34
exploiting: q-values predicted from network
-------------------------------
total reward:43
exploiting: q-values predicted from network
-------------------------------
total reward:52
exploring: random action
total reward:50
Episode: 84.01Total Reward: 50Total Steps: 9Epsilon: 0.6696478204705644
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploiting: q-values predicted from network
-------------------------------
total reward:8
exploring: random action
total reward:7
exploiting: q-values predicted from network
-------------------------------
total reward:16
exploring: random action
total reward:25
exploring: random action
total reward:23
Episode: 85.01Total Reward: 23Total Steps: 6Epsilon: 0.6662995813682115
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:17
exploiting: q-values predicted from network
-------------------------------
total reward:26
exploring: random action
total reward:24
Episode: 86.01Total Reward: 24Total Steps: 5Epsilon: 0.6629680834613705
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploiting: q-values predicted from network
-------------------------------
total reward:27
exploring: random action
total reward:26
exploiting: q-values predicted from network
-------------------------------
total reward:35
exploring: random action
total reward:33
Episode: 87.01Total Reward: 33Total Steps: 6Epsilon: 0.6596532430440636
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploring: random action
total reward:-3
Episode: 88.01Total Reward: -3Total Steps: 2Epsilon: 0.6563549768288433
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:18
exploring: random action
total reward:27
exploring: random action
total reward:36
exploring: random action
total reward:45
exploiting: q-values predicted from network
-------------------------------
total reward:54
exploring: random action
total reward:53
exploring: random action
total reward:52
exploiting: q-values predicted from network
-------------------------------
total reward:61
exploiting: q-values predicted from network
-------------------------------
total reward:59
Episode: 89.01Total Reward: 59Total Steps: 10Epsilon: 0.653073201944699
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:27
exploring: random action
total reward:25
Episode: 90.01Total Reward: 25Total Steps: 4Epsilon: 0.6498078359349755
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 91.01Total Reward: -2Total Steps: 1Epsilon: 0.6465587967553006
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:18
exploring: random action
total reward:27
exploiting: q-values predicted from network
-------------------------------
total reward:25
Episode: 92.01Total Reward: 25Total Steps: 4Epsilon: 0.6433260027715241
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 93.01Total Reward: 7Total Steps: 2Epsilon: 0.6401093727576664
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-1
exploiting: q-values predicted from network
-------------------------------
total reward:8
exploring: random action
total reward:17
exploring: random action
total reward:15
Episode: 94.01Total Reward: 15Total Steps: 4Epsilon: 0.6369088258938781
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 95.01Total Reward: 7Total Steps: 2Epsilon: 0.6337242817644086
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:9
exploiting: q-values predicted from network
-------------------------------
total reward:7
Episode: 96.01Total Reward: 7Total Steps: 2Epsilon: 0.6305556603555866
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 97.01Total Reward: -2Total Steps: 1Epsilon: 0.6274028820538087
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploring: random action
total reward:-2
Episode: 98.01Total Reward: -2Total Steps: 1Epsilon: 0.6242658676435396
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
exploiting: q-values predicted from network
-------------------------------
total reward:9
exploring: random action
total reward:7
Episode: 99.01Total Reward: 7Total Steps: 2Epsilon: 0.6211445383053219
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
actions:torch.Size([16, 6])
actions shape:torch.Size([16, 6, 1])
q-values:torch.Size([16, 6, 3])
q-expected:torch.Size([16, 6])
q-values next:torch.Size([16, 6, 3])
q-targets next:torch.Size([16, 6])
reward shape:torch.Size([16])
not done shape:torch.Size([16])
